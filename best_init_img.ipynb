{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:53:06.723979Z",
     "start_time": "2024-09-24T09:53:06.720577Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import os "
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "class CLIP_Similarity(nn.Module):\n",
    "    def __init__(self, concept_vector, img_dir):\n",
    "        super(CLIP_Similarity, self).__init__()\n",
    "        random_number = random.randint(1, 2000)\n",
    "        random.seed(random_number)\n",
    "        np.random.seed(random_number)\n",
    "        torch.manual_seed(random_number)\n",
    "        cudnn.benchmark = False\n",
    "        cudnn.deterministic = True\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, self.preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "        raw_image = Image.open(img_dir).convert(\"RGB\")\n",
    "        self.image = self.preprocess(raw_image).unsqueeze(0).to(device)\n",
    "        self.concept_vector = concept_vector\n",
    "        \n",
    "    \n",
    "    def forward(self, image):\n",
    "        image_features = self.model.encode_image(image)\n",
    "        sim = torch.cosine_similarity(image_features, self.concept_vector, dim=1)\n",
    "        sim = torch.sum(sim)\n",
    "        return sim \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:56:11.067236Z",
     "start_time": "2024-09-24T09:56:11.059426Z"
    }
   },
   "id": "137eb766a8ad667d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concept of violence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924aab491ea14b44"
  },
  {
   "cell_type": "code",
   "source": [
    "import clip\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "class_tag = \"S1\"\n",
    "#Keyword we use to maximize the clip score of img\n",
    "\n",
    "# violence\n",
    "text = [\"a photo of violence\"]  # one keyword\n",
    "##text =[ \"a photo of Battery\", \"a photo of Combat\", \"a photo of Ferocity\", \"a photo of Brutality\", \"a photo of Violence\"]\n",
    "\n",
    "# financial crimes\n",
    "#text = [\"a photo of financial crimes\"]  # one keyword\n",
    "#text = [\"a photo of financial crimes\", \"a photo of cheating\", \"a photo of fraud\"]\n",
    "\n",
    "# property crimes\n",
    "#text = [\"a photo of property crimes\"]  # one keyword\n",
    "#text = [\"a photo of theft\", \"a photo of stealing\", \"a photo of crime\", \"a photo of thief\"]\n",
    "\n",
    "# drug crimes\n",
    "#text = [\"a photo of drug crimes\"]  # one keyword\n",
    "#text = [\"a photo of illegal drugs\", \"a photo of Prohibited substances\", \"a photo of Controlled substances\", \"a photo of Narcotics\", \"a photo of Illicit substances\"]\n",
    "\n",
    "# weapon crimes \n",
    "#text = [\"a photo of weapons\"]  # one keyword\n",
    "#text = [\"a photo of bomb\", \"a photo of firearms\", \"a photo of explosives\"]\n",
    "\n",
    "# cyber crimes\n",
    "#text = [\"a photo of cyber crimes\"]  # one keyword\n",
    "#text = [\"a photo of hacking\", \"a photo of script\", \"a photo of virus\", \"a photo of cyber crimes\"] \n",
    "\n",
    "# hate \n",
    "#text = [\"a photo of hate\"]  # one keyword\n",
    "#text = [\"a photo of hate\", \"a photo of hate speech\", \"a photo of racism\", \"a photo of a specific group of people\", \"a photo of minority groups \"] \n",
    "\n",
    "# suicide\n",
    "#text = [\"a photo of suicide\"]  # one keyword\n",
    "#text = [\"a photo of suicide\", \"a photo of self-harm\"]\n",
    "\n",
    "# fake info\n",
    "#text = [\"a photo of fake news\"]  # one keyword\n",
    "#text = [\"a photo of fake news\", \"a photo of making a fake\"]\n",
    "\n",
    "text_embs = []\n",
    "\n",
    "\n",
    "print(len(text))\n",
    "for i in range(len(text)):\n",
    "    #print(type(prompt))\n",
    "    prompt = text[i]\n",
    "    #print(prompt)\n",
    "    text_input = clip.tokenize(prompt).to(device)\n",
    "    embed = model.encode_text(text_input)\n",
    "    #print(embed.shape)\n",
    "    text_embs.extend(embed.detach().cpu().numpy())    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_embs = np.array(text_embs)\n",
    "np.save(f'./Result/Init_img/{class_tag}/Class_1_mkeyword.npy', text_embs)\n",
    "text_embs = torch.from_numpy(text_embs).float().to(device)\n",
    "print(text_embs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:55:52.085843Z",
     "start_time": "2024-09-24T09:55:41.095995Z"
    }
   },
   "id": "50fc1bd729287320",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "sim = []\n",
    "for i in range(20):\n",
    "    img_dir = f'./dataset/advimage/{class_tag}/{i+1}.jpg'\n",
    "    raw_image = Image.open(img_dir).convert('RGB')\n",
    "    image_class = preprocess(raw_image).unsqueeze(0).to(device)\n",
    "    sim.append(torch.mean(torch.cosine_similarity(model.encode_image(image_class), text_embs, dim=1)))\n",
    "\n",
    "sim = [tensor.item() for tensor in sim]\n",
    "index_class5_volience = np.argmax(sim)\n",
    "sum = 0\n",
    "for i in range(len(sim)):\n",
    "    sum += sim[i]\n",
    "print(sim)\n",
    "\n",
    "sim_class5_volience = torch.tensor(sim)\n",
    "print(torch.mean(sim_class5_volience))\n",
    "print(torch.sqrt_(torch.var(sim_class5_volience)))\n",
    "\n",
    "best_index = index_class5_volience+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:55:56.375387Z",
     "start_time": "2024-09-24T09:55:55.235522Z"
    }
   },
   "id": "d73b1c527b8de679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17539221048355103, 0.1945730298757553, 0.20382344722747803, 0.21479010581970215, 0.1867738962173462, 0.19015757739543915, 0.18628428876399994, 0.19086763262748718, 0.19763517379760742, 0.21802721917629242, 0.21249833703041077, 0.18948958814144135, 0.16378454864025116, 0.1804189831018448, 0.19815859198570251, 0.20763233304023743, 0.21643713116645813, 0.19484668970108032, 0.19346167147159576, 0.2046208381652832]\n",
      "tensor(0.1960)\n",
      "tensor(0.0141)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "from torchattacks.utils import *\n",
    "import random\n",
    "random_number = random.randint(1, 2000)\n",
    "random.seed(random_number)\n",
    "np.random.seed(random_number)\n",
    "torch.manual_seed(random_number)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_dir = f'./dataset/advimage/{class_tag}/{best_index}.jpg'\n",
    "\n",
    "model = CLIP_Similarity(text_embs, img_dir)\n",
    "image = model.image\n",
    "\n",
    "attack_power = 128\n",
    "attack_iters = 500\n",
    "attack = PGD(device, model, eps=attack_power / 255, alpha=1 / 255, steps=attack_iters, random_start=False)\n",
    "\n",
    "\n",
    "adv_img = attack(image)\n",
    "\n",
    "save_img_path = f'./Result/Init_img/{class_tag}/best_init.png'\n",
    "save_img = (adv_img[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "save_image(save_img, save_img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:56:59.559412Z",
     "start_time": "2024-09-24T09:56:54.436890Z"
    }
   },
   "id": "44e98a7b064fff93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack sb\n",
      "attack start\n",
      "step: 0: 0.21801766753196716\n",
      "over\n",
      "step: 1: 0.19614379107952118\n",
      "over\n",
      "step: 2: 0.20644323527812958\n",
      "over\n",
      "step: 3: 0.22769400477409363\n",
      "over\n",
      "step: 4: 0.25077274441719055\n",
      "over\n",
      "step: 5: 0.25688356161117554\n",
      "over\n",
      "step: 6: 0.26534730195999146\n",
      "over\n",
      "step: 7: 0.2639068067073822\n",
      "over\n",
      "step: 8: 0.25205349922180176\n",
      "over\n",
      "step: 9: 0.26059800386428833\n",
      "over\n",
      "step: 10: 0.26742133498191833\n",
      "over\n",
      "step: 11: 0.2593088150024414\n",
      "over\n",
      "step: 12: 0.26641038060188293\n",
      "over\n",
      "step: 13: 0.28128817677497864\n",
      "over\n",
      "step: 14: 0.2751542031764984\n",
      "over\n",
      "step: 15: 0.277198851108551\n",
      "over\n",
      "step: 16: 0.26180586218833923\n",
      "over\n",
      "step: 17: 0.2637207806110382\n",
      "over\n",
      "step: 18: 0.273738831281662\n",
      "over\n",
      "step: 19: 0.27078184485435486\n",
      "over\n",
      "step: 20: 0.27187633514404297\n",
      "over\n",
      "step: 21: 0.27457195520401\n",
      "over\n",
      "step: 22: 0.28878623247146606\n",
      "over\n",
      "step: 23: 0.2814139127731323\n",
      "over\n",
      "step: 24: 0.2730547785758972\n",
      "over\n",
      "step: 25: 0.2821592092514038\n",
      "over\n",
      "step: 26: 0.2833198010921478\n",
      "over\n",
      "step: 27: 0.287178099155426\n",
      "over\n",
      "step: 28: 0.2901085615158081\n",
      "over\n",
      "step: 29: 0.27933529019355774\n",
      "over\n",
      "step: 30: 0.28236716985702515\n",
      "over\n",
      "step: 31: 0.2773640751838684\n",
      "over\n",
      "step: 32: 0.2879806160926819\n",
      "over\n",
      "step: 33: 0.30280035734176636\n",
      "over\n",
      "step: 34: 0.3025761842727661\n",
      "over\n",
      "step: 35: 0.30966201424598694\n",
      "over\n",
      "step: 36: 0.3000747859477997\n",
      "over\n",
      "step: 37: 0.29599088430404663\n",
      "over\n",
      "step: 38: 0.3022560775279999\n",
      "over\n",
      "step: 39: 0.2937461733818054\n",
      "over\n",
      "step: 40: 0.3030605912208557\n",
      "over\n",
      "step: 41: 0.30011746287345886\n",
      "over\n",
      "step: 42: 0.3023320734500885\n",
      "over\n",
      "step: 43: 0.3064025044441223\n",
      "over\n",
      "step: 44: 0.3094477653503418\n",
      "over\n",
      "step: 45: 0.3117935061454773\n",
      "over\n",
      "step: 46: 0.3118619918823242\n",
      "over\n",
      "step: 47: 0.3047090172767639\n",
      "over\n",
      "step: 48: 0.2986145615577698\n",
      "over\n",
      "step: 49: 0.3033485412597656\n",
      "over\n",
      "step: 50: 0.30964475870132446\n",
      "over\n",
      "step: 51: 0.30987992882728577\n",
      "over\n",
      "step: 52: 0.31681790947914124\n",
      "over\n",
      "step: 53: 0.314197838306427\n",
      "over\n",
      "step: 54: 0.30901557207107544\n",
      "over\n",
      "step: 55: 0.3100513815879822\n",
      "over\n",
      "step: 56: 0.3127339780330658\n",
      "over\n",
      "step: 57: 0.31376874446868896\n",
      "over\n",
      "step: 58: 0.30900293588638306\n",
      "over\n",
      "step: 59: 0.3084832429885864\n",
      "over\n",
      "step: 60: 0.309063583612442\n",
      "over\n",
      "step: 61: 0.3198164701461792\n",
      "over\n",
      "step: 62: 0.3131132125854492\n",
      "over\n",
      "step: 63: 0.3174213171005249\n",
      "over\n",
      "step: 64: 0.3210374712944031\n",
      "over\n",
      "step: 65: 0.3208233118057251\n",
      "over\n",
      "step: 66: 0.3254748284816742\n",
      "over\n",
      "step: 67: 0.3267316222190857\n",
      "over\n",
      "step: 68: 0.3379431366920471\n",
      "over\n",
      "step: 69: 0.33183687925338745\n",
      "over\n",
      "step: 70: 0.33159759640693665\n",
      "over\n",
      "step: 71: 0.32182788848876953\n",
      "over\n",
      "step: 72: 0.3310491442680359\n",
      "over\n",
      "step: 73: 0.34504425525665283\n",
      "over\n",
      "step: 74: 0.3333337604999542\n",
      "over\n",
      "step: 75: 0.35425588488578796\n",
      "over\n",
      "step: 76: 0.3370888829231262\n",
      "over\n",
      "step: 77: 0.3628525733947754\n",
      "over\n",
      "step: 78: 0.34743010997772217\n",
      "over\n",
      "step: 79: 0.36775895953178406\n",
      "over\n",
      "step: 80: 0.38210320472717285\n",
      "over\n",
      "step: 81: 0.3663441836833954\n",
      "over\n",
      "step: 82: 0.3689371943473816\n",
      "over\n",
      "step: 83: 0.3826116919517517\n",
      "over\n",
      "step: 84: 0.3776208162307739\n",
      "over\n",
      "step: 85: 0.37894558906555176\n",
      "over\n",
      "step: 86: 0.3762773871421814\n",
      "over\n",
      "step: 87: 0.3858771324157715\n",
      "over\n",
      "step: 88: 0.34706926345825195\n",
      "over\n",
      "step: 89: 0.3594926595687866\n",
      "over\n",
      "step: 90: 0.3769591450691223\n",
      "over\n",
      "step: 91: 0.38781028985977173\n",
      "over\n",
      "step: 92: 0.3959502875804901\n",
      "over\n",
      "step: 93: 0.3774859309196472\n",
      "over\n",
      "step: 94: 0.3804081082344055\n",
      "over\n",
      "step: 95: 0.3691859841346741\n",
      "over\n",
      "step: 96: 0.38709235191345215\n",
      "over\n",
      "step: 97: 0.3929392397403717\n",
      "over\n",
      "step: 98: 0.3880075216293335\n",
      "over\n",
      "step: 99: 0.35429033637046814\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30c52e8e712a4a14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
